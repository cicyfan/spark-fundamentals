{
  "metadata": {
    "name": "Midterm Q4",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nsc\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//read in table a\nval df \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"data/drive_stats_2019_Q1/*.csv\")\ndf.printSchema()\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//read in table b\nval df1 \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/Users/ciccy1/Data/2019-03-31.csv\").select(\"model\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//get distinct model numbers from table b \nval model \u003d df1.distinct().collect()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.util.sketch.BloomFilter\n//inititate bloom filter\nval bf \u003d BloomFilter.create(model.length)\n//put model names in bloom filter\nfor (i \u003c- 0 until model.length) {\n    bf.put(model(i)(0))\n}\n\n//define broadcast variable\nval broadcastVar \u003d sc.broadcast(bf)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//bloom filter bit size and expected false positive\nprint(bf.bitSize())  \nprint(bf.expectedFpp())"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//define BloomFilter.mightContain into a UDF \ndef might_contain(f: org.apache.spark.util.sketch.BloomFilter) \u003d udf((model: String) \u003d\u003e \n  if(model !\u003d null) f.mightContain(model) else false)\n//apply bloom filter on table A\nval filtered \u003d df.filter(might_contain(broadcastVar.value)($\"model\"))\n//show filtered table A\nfiltered.select(\"date\", \"model\", \"serial_number\").show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//sanity check \ndf.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//sanity check: filtered df row number is less than the original df\nfiltered.count()\n"
    }
  ]
}